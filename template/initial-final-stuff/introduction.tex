\begin{quotation}
  {\footnotesize
    \noindent{\emph{``All models are wrong, but some are useful.''\\}
    }
    \begin{flushright}
      George Box
    \end{flushright}
  }
\end{quotation}
\vspace{0.5cm}

\section{Motivation}
Nowadays, different classes of missions envision a major role for close-rang proximity operations, like \acrfull{ff} \cite{2001FormationFliying}  \cite{2009FormationFliying}, \acrfull{oos} \cite{auricchio} \cite{Zimpfer2005} \cite{Tatsch2006} \cite{FloresAbad2014} and \acrfull{adr} \cite{clerc2012astrium} \cite{Bonnal2013}.
In the past, most of the missions belonging to those categories were possible thanks to the presence of on-board crew, or the active cooperativeness between \acrshort{sc}.
In a typical scenario, the \acrshort{sc} which is being serviced is referred as "target" or "client", while the \acrshort{sc} which is performing the approach is referred as "chaser" or "servicer". A target is deemed cooperative if it is built to provide information suitable for the estimation of its distance and orientation in space with respect to the chaser \acrshort{sc}. Also, it can be be actively or passively cooperative depending on whether it interacts with a dedicated radio-link with the chaser \acrshort{sc} or not \cite{Opromolla2017}.
As regard to the new generation of space robotics missions such as debris removal and \acrshort{oos}, proximity operations and docking are key-enabling capabilities for either repair, refuel or deorbit end-of-life and nonfunctional \acrshort{sc} \cite{2016Ventura}.
The main challenge when performing close-range operations in actual \acrshort{oos} and \acrshort{adr} missions is when the target \acrshort{sc} may be uncooperative.
This implies that the target may not be equipped with an active communication link or identifiable markers such as light-emitting diodes or corner cube reflectors to help in computing the relative position and attitude of the active \acrshort{sc} (chaser) with respect to the uncooperative target \cite{2019phdSharma}.
Another important aspect, which comes out when dealing with uncooperative targets, is that debris or operating \acrshort{sc} to be serviced may have suffered physical damages as well as optical degradation of their surfaces due to the prolonged exposure to the space environment, thus appearing different than expected \cite{Opromolla2017}.
Thus, when operating in close-proximity the attitude and the motion of the target must be estimated in autonomy by exploiting the sensors available on the \acrshort{sc} actively performing the servicing maneuvers.
With regards to the technological aspects, \acrfull{eo} sensors have been identified as the best option for relative navigation in the foredescribed scenario \cite{Opromolla2017} \cite{pesciolino}.
Either active Light Detection and Ranging (LIDAR) systems or passive monocular and stereo cameras can be used. The selection of the navigation sensor must consider the resources available on-board in terms of mass, electrical power and computational capability, bu also the mission scenario and the costs associated to the design and development \cite{clerc2012astrium} \cite{pesciolino}.
As stated in \cite{Sharma2016} monocular vision navigation has been identified as an enabling technology for present and future \acrshort{ff} and \acrshort{oos} missions (namely PROBA-3 by ESA \cite{Casti2019}, PRISMA by OHB Sweden \cite{2013Damico}).
Monocular navigation on such missions relies on finding an estimate of the initial pose of the space resident object with respect to the camera, based on a minimum number of features from a 3D computer model and a single 2D image \cite{Sharma2016}.
In contrast to other state-of-the-art systems based on \acrfull{lidar} or stero camera sensors, monocular navigation ensures rapid pose determination while offering some advantages such as lower hardware complexity, cost, weight and power consumption, possibility to be simultaneously used for supervised applications and a much larger operational range, not limited by the size of the platform \cite{Sharma2018} \cite{2016Ventura} \cite{pesciolino}.
However, the benefit of lower hardware complexity trades off with increased algorithmic complexity since a monocular sensor cannot provide direct three-dimensional (3D) measurements about the target.
Moreover, monocular sensors can be less robust to adverse illumination conditions typical of the space environment \cite{Volpe2017} (e.g., saturation under direct Sun illumination, or absence of light during eclipse) \cite{pesciolino}.
The increasing challenges of space exploration and moreover the urgent need for debris removal to free slots in orbit and to avoid unwanted collisions is what mainly motivate this work.
The capability of being able to develop and test pose determination algorithm in fact will be a key factor for the overall success of new generation missions. Thus, this work is motivated from the need to implement a low-cost, reliable and extendable solution for simulating low Earth orbit spaceborne imagery for \acrfull{cv} algorithms needs.

\section{Problem Statement}
The availability of a tool capable of rendering images of a target  \acrshort{sc} is of vital importance for the implementation and testing of any kind of \acrshort{cv} algorithm.
The usage of artificial in images in fact gives a complete control over the scene and more importantly, recently investigated deep learning techniques relies on very huge annotated data-sets of images. The main difficulties when searching for suitable data-sets arises from the difficulty of acquiring thousands of spaceborne images of the desired target \acrshort{sc} with accurately annotated pose labels and with an high enough degree of realism, capable of being representative of real operative conditions. A poorly made data-set in fact can lead to incoherent results due to wrong assumptions, especially when developing techniques which are based on the implementation algorithms relying on Neural Networks. Moreover, a standard tool capable of generating thousands of images at demands enable the user to systematically evaluate and compare the performance of different algorithms.
So, in this thesis the possibility of generating an accurate enough data-set by employing Ray-Tracing techniques is firstly explored. Then, the developed instrument it is tested against a real world use case scenario, which is the determination of the unknown \acrshort{3d} pose a non-cooperative target (no markers or other specific supportive means) using a single \acrfull{2d} image, given the target's \acrfull{3d} geometrical representation (referred as map or model) by developing a customized implementation of the \acrshort{svd} monocular pose initialization algorithm for uncooperative \acrshort{sc}. The algorithm extracts notable image points (features) and compares them with the target map (stored on-board the servicer). The task is non trivial, because the relationship between the image points and pose parameters is highly non linear, and the problem of retrieving the \acrshort{3d} points from the \acrshort{2d} image can have infinite solution in under-constrained situations \cite{10.1145/358669.358692}.

\section{Structure of the Thesis}
The thesis is divided into four chapters. The \hyperref[chap:first-chapter]{first chapter} presents to the reader a brief overview on the current state-of-art status for what concerns synthetic images generation for spaceborne applications as well as the autonomous close-proximity relative navigation problem. The \hyperref[chap:second-chapter]{second chapter} is completely focused on the image generation problem, with an in-dept explanation regarding the toolbox developed to allow the end user to produce image data-sets starting from the CAD model of the target \acrshort{sc}. The \hyperref[chap:third-chapter]{third chapter} is dedicated to the analysis and the implementation of the \acrshort{svd} architecture for solving the pose initialization problem when considering non cooperative \acrshort{sc}. The \hyperref[chap:fourth-chapter]{fourth chapter} illustrates the results obtained when using the pose initialization algorithm on the generated images. The thesis \hyperref[chap:conclusions]{ends} with a depiction of the possible future developments that can be performed on both the synthetic images and the algorithm.